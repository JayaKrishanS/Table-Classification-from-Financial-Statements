{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNiiAopL4OFpnn73Q05P/I7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JayaKrishanS/Table-Classification-from-Financial-Statements/blob/main/test_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-b6l_x874bY",
        "outputId": "8d7e7ff3-f3f1-4625-9801-f67d1659acfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the HTML file path: /content/18391125_2.html\n",
            "consolidated standalone particulars assets current assets property plant equipment capital work progress goodwill intangible assets intangible assets under development financial assets investments loans other financial assets deferred assets income assets other current assets total current assets current assets inventories financial assets investments trade receivables cash cash equivalents other bank balances loans other financial assets other current assets total current assets total assets equity liabilities equity equity share capital other equity equity attributable shareholders company controlling interests total equity current liabilities financial liabilities borrowings other financial liabilities provisions deferred liabilities income liabilities other current liabilities total current liabilities current liabilities financial liabilities borrowings trade payables other financial liabilities income liabilities provisions other current liabilities total current liabilities total liabilities total equity liabilities\n",
            "consolidated standalone particular asset current asset property plant equipment capital work progress goodwill intangible asset intangible asset under development financial asset investment loan other financial asset deferred asset income asset other current asset total current asset current asset inventory financial asset investment trade receivables cash cash equivalent other bank balance loan other financial asset other current asset total current asset total asset equity liability equity equity share capital other equity equity attributable shareholder company controlling interest total equity current liability financial liability borrowing other financial liability provision deferred liability income liability other current liability total current liability current liability financial liability borrowing trade payable other financial liability income liability provision other current liability total current liability total liability total equity liability\n",
            "Balance Sheets\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import sys\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('wordnet', quiet=True)\n",
        "\n",
        "\n",
        "# Importing the model and TF-IDF file\n",
        "model = pickle.load(open('model.pkl', 'rb'))\n",
        "vectorizer = pickle.load(open('vectorizer.pkl', 'rb'))\n",
        "\n",
        "def extract_words_from_html(file_path):\n",
        "    \"\"\"Extract words from a single HTML file, excluding numbers.\"\"\"\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        html_content = file.read()\n",
        "\n",
        "    # Parse the HTML content and extract all text\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "    text = soup.get_text()\n",
        "\n",
        "    # Clean the extracted text to keep only words and exclude numbers\n",
        "    words_list = re.findall(r'\\b[a-zA-Z]+\\b', text)\n",
        "    words = ' '.join(words_list)\n",
        "    return words\n",
        "\n",
        "\n",
        "def prediction(file_path):\n",
        "    words = extract_words_from_html(file_path)\n",
        "\n",
        "    #Changing into lower case\n",
        "    words = words.lower()\n",
        "    #removing words less than three letters\n",
        "    words_list = words.split()\n",
        "    filtered_words = [word for word in words_list if len(word) > 3]\n",
        "    words= ' '.join(filtered_words)\n",
        "    print(words)\n",
        "    #Applying lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_words = ' '.join([lemmatizer.lemmatize(word) for word in words.split()])\n",
        "    print(lemmatized_words)\n",
        "    input_features = vectorizer.transform([lemmatized_words])\n",
        "    input_prediction = model.predict(input_features)\n",
        "\n",
        "    if input_prediction[0] == 0:\n",
        "        print(\"Balance Sheets\")\n",
        "    elif input_prediction[0] == 1:\n",
        "        print(\"Cash Flow\")\n",
        "    elif input_prediction[0] == 2:\n",
        "        print(\"Income Statement\")\n",
        "    elif input_prediction[0] == 3:\n",
        "        print(\"Notes\")\n",
        "    else:\n",
        "        print(\"Others\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    if len(sys.argv) == 2:\n",
        "        file_path = sys.argv[1]\n",
        "    else:\n",
        "        file_path = input(\"Enter the HTML file path: \")\n",
        "        prediction(file_path)"
      ]
    }
  ]
}